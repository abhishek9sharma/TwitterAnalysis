{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell collects 1800 Tweets as per the below conditions\n",
    "-  each tweet contains one of the following hashtags #Service, #price, #cost, #quality, #ambiente, #reservation\n",
    "-  each tweet has atleast 2 likes and atleast 16 characters (same as greater than 15 characters)\n",
    "- the cell also prints the range of likes for the collected data i.e. the tweet id with the lowes number of likes and highest number of likes\n",
    "- tweets are stored as JSON in individual files('Data/JSON/') \n",
    "- tweet content and some metadata is stored in one file (tweet content only 'Data/alltweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Tweets for hashtag #reservation\n",
      " error occured while extracting tweets using  3 <tweepy.api.API object at 0x7fe94c43f3c8>\n",
      "0 tweets extracted for hashtag #reservation\n",
      "\n",
      "Collecting Tweets for hashtag #cost\n",
      " error occured while extracting tweets using  1 <tweepy.api.API object at 0x7fe94c430ba8>\n",
      "0 tweets extracted for hashtag #cost\n",
      "\n",
      " Minimum Likes found are  2  for tweet id  {'val': 2, 'id': '1095887246610309120'}\n",
      " Maximum Likes found are  -inf  for tweet id  {'val': -inf, 'id': ''}\n"
     ]
    }
   ],
   "source": [
    "#DATA COLLECTION\n",
    "from getdata import TweetExtractor\n",
    "\n",
    "\n",
    "#Collect Data \n",
    "#htlist = ['Service', 'price', 'quality', 'ambiente', 'reservation', 'cost']\n",
    "htlist = ['reservation', \"cost\"]\n",
    "data_collector = TweetExtractor(minlikes = 2, mincharlen = 16, tweetstofind = 300, configfilepath= 'config.json', datafolder= 'Data/', idsprocessedfile ='idsprocessedalready.txt', writeheader = True)\n",
    "data_collector.InitiateAPIHAndlers()\n",
    "for ht in htlist:\n",
    "    print( \"Collecting Tweets for hashtag #\" + ht)\n",
    "    print(str(data_collector.ExtractTweets('#'+ht)) + \" tweets extracted for hashtag #\" + ht)\n",
    "    print()\n",
    "\n",
    "    \n",
    "#Print Range \n",
    "minlikes = data_collector.rangeoflikes['min']\n",
    "maxlikes = data_collector.rangeoflikes['max']\n",
    "print (' Minimum Likes found are ', minlikes['val'], \" for tweet id \", minlikes)\n",
    "print (' Maximum Likes found are ', maxlikes['val'], \" for tweet id \", maxlikes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell is used just to validate collected data. & inavlid Tweets were found which contained '#RÃ©servation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No invalid files found Total valid tweets collected are  1550\n"
     ]
    }
   ],
   "source": [
    "#Validate Collected Data\n",
    "import json \n",
    "import os\n",
    "datafolder = 'Data/JSON/'\n",
    "def CheckHashTag(tweet):\n",
    "    htlist = ['Service', 'price', 'cost', 'quality', 'ambiente', 'reservation']\n",
    "    tweettext = tweet['full_text'].lower()\n",
    "    for t in htlist:\n",
    "        ht = '#'+t.lower()\n",
    "        if ht in tweettext:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "files = os.listdir(datafolder)\n",
    "files_to_check = len(files)\n",
    "valid_files = 0\n",
    "invalid_tweets = []\n",
    "for tweetfile in files:\n",
    "    jsonpath = datafolder + tweetfile\n",
    "    tweetjson = json.loads(open(jsonpath,'r').read())\n",
    "    if len(tweetjson['full_text'])<16 or tweetjson['favorite_count']<2 or not(CheckHashTag(tweetjson)):\n",
    "        invalid_tweets.append(tweetjson)\n",
    "        #print(\"Buggy Tweet found : \", tweetjson['full_text'].replace('\\n','').strip())\n",
    "    else:\n",
    "        valid_files+=1\n",
    "    \n",
    "        \n",
    "if valid_files == files_to_check:\n",
    "    print ( \"No invalid files found Total valid tweets collected are \", valid_files)\n",
    "else:\n",
    "    print(files_to_check - valid_files ,\" Invalid files found \")\n",
    "    for t in invalid_tweets:\n",
    "        pass\n",
    "        print(t['id_str'],t['full_text'].replace('\\n','').strip())\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
