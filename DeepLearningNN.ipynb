{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple Deep Learning Model for Classifying Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Code : Import Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user.friends_count</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>user.listed_count</th>\n",
       "      <th>text_features</th>\n",
       "      <th>text_features_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharing my #Walk with #K9Jinkyüêæ \\nMy #Service,...</td>\n",
       "      <td>POS</td>\n",
       "      <td>23</td>\n",
       "      <td>9930</td>\n",
       "      <td>9925</td>\n",
       "      <td>28</td>\n",
       "      <td>sharing my walk with k9jinky  my service  bran...</td>\n",
       "      <td>sharing my walk with k9jinky my service branch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With this new IoT-based crash detection #servi...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6465</td>\n",
       "      <td>96</td>\n",
       "      <td>with this new iotbased crash detection service...</td>\n",
       "      <td>with this new iotbased crash detection service...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text sentiment  retweet_count  \\\n",
       "0  Sharing my #Walk with #K9Jinkyüêæ \\nMy #Service,...       POS             23   \n",
       "1  With this new IoT-based crash detection #servi...       NEG              1   \n",
       "\n",
       "   user.friends_count  user.followers_count  user.listed_count  \\\n",
       "0                9930                  9925                 28   \n",
       "1                  10                  6465                 96   \n",
       "\n",
       "                                       text_features  \\\n",
       "0  sharing my walk with k9jinky  my service  bran...   \n",
       "1  with this new iotbased crash detection service...   \n",
       "\n",
       "                                   text_features_new  \n",
       "0  sharing my walk with k9jinky my service branch...  \n",
       "1  with this new iotbased crash detection service...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code Load Data\n",
    "tweetsInfo = pd.read_csv('AllTweetInfo.csv')\n",
    "tweetsInfo.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Features and Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get Input Featurs\n",
    "ftr_col = 'text_features'\n",
    "tokenizer = Tokenizer(split=' ')\n",
    "tokenizer.fit_on_texts(tweetsInfo[ftr_col].values)\n",
    "X_t = tokenizer.texts_to_sequences(tweetsInfo[ftr_col].values)\n",
    "X_padded = pad_sequences(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Creat Train and Validation Split\n",
    "y = pd.get_dummies(tweetsInfo['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_padded,y, test_size = 0.3, random_state = 27)\n",
    "#print(X_train.shape,Y_train.shape)\n",
    "#print(X_test.shape,Y_test.shape)\n",
    "val_size = 100\n",
    "X_validate = X_test[-val_size:]\n",
    "Y_validate = Y_test[-val_size:]\n",
    "X_test = X_test[:-val_size]\n",
    "Y_test = Y_test[:-val_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def CreateModel(X_shape):\n",
    "    lstm_out1, lstm_out2, l1, l2, em = 196,196,2,2,56    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_fatures, em, input_length = X_shape))\n",
    "    model.add(LSTM(lstm_out1, dropout=0.2))\n",
    "    model.add(Dense(l1,activation='relu'))\n",
    "    model.add(Dense(l2,activation='relu'))\n",
    "   \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "    \n",
    "# embed_dim = 56\n",
    "# lstm_out1 = 196\n",
    "# lstm_out2 = 196\n",
    "# l1 = 2\n",
    "# l2 = 2\n",
    "# X_shape = X_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 54, 56)            112000    \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 196)               198352    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 394       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 310,752\n",
      "Trainable params: 310,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Training Model\n",
      "Epoch 1/10\n",
      " - 8s - loss: 2.5513 - acc: 0.8157\n",
      "Epoch 2/10\n",
      " - 4s - loss: 2.5883 - acc: 0.8394\n",
      "Epoch 3/10\n",
      " - 4s - loss: 2.5883 - acc: 0.8394\n",
      "Epoch 4/10\n",
      " - 4s - loss: 2.5883 - acc: 0.8394\n",
      "Epoch 5/10\n",
      " - 3s - loss: 2.5883 - acc: 0.8394\n",
      "Epoch 6/10\n",
      " - 4s - loss: 2.5883 - acc: 0.8394\n",
      "Epoch 7/10\n",
      " - 3s - loss: 2.5883 - acc: 0.8394\n",
      "Epoch 8/10\n",
      " - 3s - loss: 2.5883 - acc: 0.8394\n",
      "Epoch 9/10\n",
      " - 3s - loss: 2.5883 - acc: 0.8394\n",
      "Epoch 10/10\n",
      " - 4s - loss: 2.5883 - acc: 0.8394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper Functin For Model Creation\n",
    "def CreatModel(batch_size, epochs, X_shape, X_train, Y_train):\n",
    "    #model = KerasClassifier(build_fn = CreateModel)\n",
    "    currmodel = CreateModel(X_shape)\n",
    "    print(currmodel.summary())\n",
    "    print()   \n",
    "\n",
    "    print('Training Model')\n",
    "    currmodel.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose = 2)\n",
    "    print()\n",
    "    return currmodel\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_shape = X_padded.shape[1]\n",
    "m = CreatModel(32, 10, X_shape, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution Scores\n",
      "score: 2.98\n",
      "acc: 0.81\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalution Scores\")\n",
    "score,acc = m.evaluate(X_test, Y_test, verbose = 2, batch_size = 32)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # define the grid search parameters\n",
    "#     param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "#     grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "#     grid_result = grid.fit(X_train, Y_train)\n",
    "#     print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# epochs = [10, 50, 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# epochs = [10, 50, 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creat_train_eval(lstm_out1, lstm_out2, l1, l2, em, batchsize,X_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN = KerasClassifier(build_fn=CreateModel, verbose=0)\n",
    "\n",
    "\n",
    "# #Defualt Params\n",
    "\n",
    "# batchsize = 32\n",
    "\n",
    "# # Params to be Tuned\n",
    "# epochs = [5, 10]\n",
    "# batches = [5, 10, 100]\n",
    "# optimizers = ['rmsprop', 'adam']\n",
    "\n",
    "\n",
    "# # Tune Params\n",
    "# hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "# grid = GridSearchCV(estimator=NN, param_grid=hyperparameters)\n",
    "# grid_result = grid.fit(X_train, Y_train)\n",
    "# grid_result.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.55\n",
      "acc: 0.81\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
